{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield Curve</th>\n",
       "      <th>Production Index</th>\n",
       "      <th>Housing Starts</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Business Confidence</th>\n",
       "      <th>Producer Price Index</th>\n",
       "      <th>Export Price Index</th>\n",
       "      <th>Import Price Index</th>\n",
       "      <th>Basic Price Index for Domestic Goods</th>\n",
       "      <th>USD</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>CNY</th>\n",
       "      <th>OMX Helsinki</th>\n",
       "      <th>Consumer Price Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan.00</th>\n",
       "      <td>0.62</td>\n",
       "      <td>96.01601</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1466</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13</td>\n",
       "      <td>91.1</td>\n",
       "      <td>110.2</td>\n",
       "      <td>85.9</td>\n",
       "      <td>79.1</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>106.53</td>\n",
       "      <td>0.61834</td>\n",
       "      <td>8.3926</td>\n",
       "      <td>14364.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb.00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>96.31606</td>\n",
       "      <td>118.2</td>\n",
       "      <td>1476</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20</td>\n",
       "      <td>92.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>87.2</td>\n",
       "      <td>79.9</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>107.64</td>\n",
       "      <td>0.61466</td>\n",
       "      <td>8.1408</td>\n",
       "      <td>15864.0</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar.00</th>\n",
       "      <td>0.45</td>\n",
       "      <td>95.51592</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1485</td>\n",
       "      <td>10.2</td>\n",
       "      <td>17</td>\n",
       "      <td>93.5</td>\n",
       "      <td>114.4</td>\n",
       "      <td>87.9</td>\n",
       "      <td>80.3</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>102.59</td>\n",
       "      <td>0.61063</td>\n",
       "      <td>7.9834</td>\n",
       "      <td>17092.0</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr.00</th>\n",
       "      <td>0.22</td>\n",
       "      <td>97.01617</td>\n",
       "      <td>119.3</td>\n",
       "      <td>1490</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>93.9</td>\n",
       "      <td>115.1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>99.92</td>\n",
       "      <td>0.59802</td>\n",
       "      <td>7.8402</td>\n",
       "      <td>15799.0</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May.00</th>\n",
       "      <td>0.11</td>\n",
       "      <td>101.21690</td>\n",
       "      <td>120.5</td>\n",
       "      <td>1497</td>\n",
       "      <td>9.8</td>\n",
       "      <td>19</td>\n",
       "      <td>93.8</td>\n",
       "      <td>114.6</td>\n",
       "      <td>89.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>98.09</td>\n",
       "      <td>0.60151</td>\n",
       "      <td>7.4996</td>\n",
       "      <td>16344.0</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yield Curve  Production Index  Housing Starts  Cost of Living Index  \\\n",
       "Period                                                                        \n",
       "Jan.00         0.62          96.01601           118.4                  1466   \n",
       "Feb.00         0.53          96.31606           118.2                  1476   \n",
       "Mar.00         0.45          95.51592           118.4                  1485   \n",
       "Apr.00         0.22          97.01617           119.3                  1490   \n",
       "May.00         0.11         101.21690           120.5                  1497   \n",
       "\n",
       "        Unemployment  Business Confidence  Producer Price Index  \\\n",
       "Period                                                            \n",
       "Jan.00          10.1                   13                  91.1   \n",
       "Feb.00          10.2                   20                  92.9   \n",
       "Mar.00          10.2                   17                  93.5   \n",
       "Apr.00          10.0                   15                  93.9   \n",
       "May.00           9.8                   19                  93.8   \n",
       "\n",
       "        Export Price Index  Import Price Index  \\\n",
       "Period                                           \n",
       "Jan.00               110.2                85.9   \n",
       "Feb.00               113.3                87.2   \n",
       "Mar.00               114.4                87.9   \n",
       "Apr.00               115.1                87.4   \n",
       "May.00               114.6                89.2   \n",
       "\n",
       "        Basic Price Index for Domestic Goods     USD     JPY      GBP     CNY  \\\n",
       "Period                                                                          \n",
       "Jan.00                                  79.1  1.0137  106.53  0.61834  8.3926   \n",
       "Feb.00                                  79.9  0.9834  107.64  0.61466  8.1408   \n",
       "Mar.00                                  80.3  0.9643  102.59  0.61063  7.9834   \n",
       "Apr.00                                  80.2  0.9470   99.92  0.59802  7.8402   \n",
       "May.00                                  81.0  0.9060   98.09  0.60151  7.4996   \n",
       "\n",
       "        OMX Helsinki  Consumer Price Index  \n",
       "Period                                      \n",
       "Jan.00       14364.0                  98.0  \n",
       "Feb.00       15864.0                  98.8  \n",
       "Mar.00       17092.0                  99.3  \n",
       "Apr.00       15799.0                  99.6  \n",
       "May.00       16344.0                  99.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = pd.read_csv('Additional.csv', index_col=\"Period\")\n",
    "inflation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 277 entries, Jan.00 to Jan.23\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Yield Curve                           277 non-null    float64\n",
      " 1   Production Index                      277 non-null    float64\n",
      " 2   Housing Starts                        277 non-null    float64\n",
      " 3   Cost of Living Index                  277 non-null    int64  \n",
      " 4   Unemployment                          277 non-null    float64\n",
      " 5   Business Confidence                   277 non-null    int64  \n",
      " 6   Producer Price Index                  277 non-null    float64\n",
      " 7   Export Price Index                    277 non-null    float64\n",
      " 8   Import Price Index                    277 non-null    float64\n",
      " 9   Basic Price Index for Domestic Goods  277 non-null    float64\n",
      " 10  USD                                   277 non-null    float64\n",
      " 11  JPY                                   277 non-null    float64\n",
      " 12  GBP                                   277 non-null    float64\n",
      " 13  CNY                                   277 non-null    float64\n",
      " 14  OMX Helsinki                          277 non-null    float64\n",
      " 15  Consumer Price Index                  277 non-null    float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 36.8+ KB\n"
     ]
    }
   ],
   "source": [
    "inflation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.3558571428571424\n",
      "MAE of Decision Tree 0.3414285714285709\n",
      "R-Squared of Decision Tree 0.9978083516445174\n"
     ]
    }
   ],
   "source": [
    "X = inflation.drop('Consumer Price Index', axis=1)\n",
    "y = inflation['Consumer Price Index']\n",
    "\n",
    "\n",
    "#creating the x and y value for the dataset and creating a test and training set from them\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit (X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "inflation_tree = DecisionTreeRegressor(random_state=42,)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit (X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [19.77267857 17.0275     56.55436364 25.63427273 66.888     ]\n",
      "Mean CV Score: 37.175362987013\n",
      "Standard Deviation: 20.49572168345582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42, max_depth=10, min_samples_leaf=1, criterion='mse', splitter='random')\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(dt_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [14.76114068  2.1856422  10.2877184   4.61849715 65.37109409]\n",
      "Mean CV Score: 19.444818502272703\n",
      "Standard Deviation: 23.378242369410412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=15, min_samples_leaf=1, max_features='auto')\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [0.05499648 0.00344346 0.00120279 0.0033938  0.01650938]\n",
      "Mean CV Score: 0.015909180877574508\n",
      "Standard Deviation: 0.02028045486225236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_regressor = Lasso(alpha=0.01, fit_intercept=True, max_iter=1000, normalize=False, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(lasso_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [0.3522588  0.86684972 0.14020571 0.02638506 0.12225635]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0q/7yfv43d952dbrjwdnvllyvq40000gn/T/ipykernel_56271/290840051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Print the cross-validation scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV Scores:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean CV Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Standard Deviation:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'median'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_regressor = SVR(C=10, epsilon=0.01, kernel='linear')\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(svr_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [ 8.10877603  5.86686176  4.95655548  0.47631415 61.57336988]\n",
      "Mean CV Score: 16.19637545988757\n",
      "Standard Deviation: 22.823819227434324\n"
     ]
    }
   ],
   "source": [
    "import xgboost as XGB\n",
    "\n",
    "xgb_regressor = XGB.XGBRegressor(learning_rate=0.1, max_depth=5, min_child_weight=1)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(xgb_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [2.29071537e-02 5.13963357e+00 2.55824307e-03 1.57197974e-03\n",
      " 1.39025145e-01]\n",
      "Mean CV Score: 1.0611392184335773\n",
      "Standard Deviation: 2.03988297593114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(50, 50), activation='relu', solver='lbfgs', max_iter=5000, learning_rate='constant', alpha=0.01, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(mlp_regressor, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the scores from negative MSE to positive MSE\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('CV Scores:', cv_scores)\n",
    "print('Mean CV Score:', cv_scores.mean())\n",
    "print('Standard Deviation:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield Curve 0.38389137760866404\n",
      "Production Index 0.2338662368453517\n",
      "Housing Starts 0.3451105995254318\n",
      "Cost of Living Index -1.9854179332327795\n",
      "Unemployment 0.30138974626392745\n",
      "Business Confidence 0.17407492902953747\n",
      "Producer Price Index 0.035075680965986664\n",
      "Export Price Index 0.06233464690834232\n",
      "Import Price Index 0.12546619761555997\n",
      "Basic Price Index for Domestic Goods 0.16091866014314155\n",
      "USD 0.14636623981077293\n",
      "JPY 0.1968600274628737\n",
      "GBP 0.24810788210461998\n",
      "CNY 0.3530466274084203\n",
      "OMX Helsinki 0.21890908154014926\n"
     ]
    }
   ],
   "source": [
    "# get the feature importances\n",
    "importances = model.coefs_[0].sum(axis=1)\n",
    "\n",
    "# normalize the importances\n",
    "importances /= importances.sum()\n",
    "\n",
    "# print the importances\n",
    "for feature, importance in zip(heading, importances):\n",
    "    print(feature, importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of tree: 11\n",
      "Number of nodes in tree: 311\n"
     ]
    }
   ],
   "source": [
    "print('Depth of tree:', inflation_tree.tree_.max_depth)\n",
    "print('Number of nodes in tree:', inflation_tree.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param: {'criterion': 'mse', 'max_depth': 10, 'min_samples_leaf': 1, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "param_dt = {'max_depth': [2, 4, 6, 8, 10, 11], 'min_samples_leaf': [1, 2, 5, 10, 15, 20, 25], 'criterion': ['mse', 'friedman_mse'], 'splitter': ['best', 'random'], }\n",
    "grid_dt = GridSearchCV(estimator=inflation_tree, param_grid=param_dt, scoring='neg_mean_squared_error')\n",
    "grid_result = grid_dt.fit(X_train_scaled, y_train)\n",
    "print ('Best Param:', grid_result.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(random_state=42, max_depth=10, min_samples_leaf=1, criterion='mse', splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.17828571428571438\n",
      "MAE of Decision Tree 0.254285714285713\n",
      "R-Squared of Decision Tree 0.9989019762554627\n"
     ]
    }
   ],
   "source": [
    "inflation_tree = DecisionTreeRegressor(random_state=42, max_depth=11, min_samples_leaf=1, criterion='mse', splitter='best')\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.29725137142858754\n",
      "MAE of Random Forest: 0.25228571428572116\n",
      "R-squared 0.9981692921093959\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inflation_random = RandomForestRegressor(random_state=42)\n",
    "inflation_random.fit(X_train_scaled, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test_scaled)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result is obtained using {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(max_depth = [1, 5, 10, 15], min_samples_leaf = [1, 5, 10, 15, 20], n_estimators = [100, 200, 300], max_features= ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "forest_est = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=inflation_random, param_grid=grid, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is obtained using\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.2553169205601701\n",
      "MAE of Random Forest: 0.24244551020409924\n",
      "R-squared 0.9984275574614581\n"
     ]
    }
   ],
   "source": [
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=10, min_samples_leaf=1, max_features='auto')\n",
    "inflation_random.fit(X_train, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.30137754285716073\n",
      "MAE of Random Forest: 0.2608285714285783\n",
      "R-squared 0.9981438798983236\n"
     ]
    }
   ],
   "source": [
    "inflation_random = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=15, min_samples_leaf=1, max_features='auto')\n",
    "inflation_random.fit(X_train, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 22.591925512483385\n",
      "MAE of LASSO Forest: 4.242300042507948\n",
      "R-Squared of Lasso 0.8608611422013919\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(random_state=42, )\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combination: {'alpha': 0.01, 'fit_intercept': False, 'max_iter': 5000, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [1000, 5000, 10000],\n",
    "}\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(inflation_lasso, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameter combination found\n",
    "print(\"Best parameter combination:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 0.011009331479272933\n",
      "MAE of LASSO Forest: 0.06671267319508647\n",
      "R-Squared of Lasso 0.9999321958720913\n"
     ]
    }
   ],
   "source": [
    "#After manual tuning\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(alpha=0.01, fit_intercept=True, max_iter=1000, normalize=False, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 146.16507737840195\n",
      "MAE of LASSO Forest: 9.483979663512144\n",
      "R-Squared of Lasso 0.0998004173996373\n"
     ]
    }
   ],
   "source": [
    "inflation_lasso = Lasso(alpha=0.01, fit_intercept=False, max_iter=5000, normalize=True, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6.821893575349972\n",
      "MAE: 2.242964061611064\n",
      "R-squared: 0.957985410337274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Initial Data.csv')\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = data[['Yield Curve', 'Production Index', 'Housing Starts', 'Cost of Living Index', 'Unemployment']]\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVR model with chosen hyperparameters\n",
    "svr = SVR(kernel='linear', C=1, epsilon=0.01, )\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10.676229437066187\n",
      "MAE: 1.5744103005857342\n",
      "R-squared: 0.9342473766280589\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Initial Data.csv')\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = data[['Yield Curve', 'Production Index', 'Housing Starts', 'Cost of Living Index', 'Unemployment']]\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVR model with chosen hyperparameters\n",
    "svr = SVR()\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'epsilon': 0.01, 'kernel': 'linear'}\n",
      "SVR(C=10, epsilon=0.01, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = inflation\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = data[['Yield Curve', 'Production Index', 'Housing Starts', 'Cost of Living Index', 'Unemployment']]\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a dictionary of hyperparameters and their possible values\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [0.1, 1, 2, 3, 4, 5, 10], 'epsilon': [0.01, 0.1, 1]}\n",
    "\n",
    "# Create an SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Use GridSearchCV to find the best combination of hyperparameters\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print (best_params)\n",
    "print (best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0070528073078013195\n",
      "MAE: 0.04232232962774946\n",
      "R-squared: 0.9999565632618371\n"
     ]
    }
   ],
   "source": [
    "svr = SVR (C=10, epsilon=0.01, kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006657303867834006\n",
      "MAE: 0.04092340885671218\n",
      "R-squared: 0.999958999083293\n"
     ]
    }
   ],
   "source": [
    "svr = SVR (C=20, epsilon=0.0341, kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
