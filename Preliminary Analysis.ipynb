{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield Curve</th>\n",
       "      <th>Production Index</th>\n",
       "      <th>Housing Starts</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Consumer Price Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan.00</th>\n",
       "      <td>0.62</td>\n",
       "      <td>96.01601</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1466</td>\n",
       "      <td>10.1</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb.00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>96.31606</td>\n",
       "      <td>118.2</td>\n",
       "      <td>1476</td>\n",
       "      <td>10.2</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar.00</th>\n",
       "      <td>0.45</td>\n",
       "      <td>95.51592</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1485</td>\n",
       "      <td>10.2</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr.00</th>\n",
       "      <td>0.22</td>\n",
       "      <td>97.01617</td>\n",
       "      <td>119.3</td>\n",
       "      <td>1490</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May.00</th>\n",
       "      <td>0.11</td>\n",
       "      <td>101.21690</td>\n",
       "      <td>120.5</td>\n",
       "      <td>1497</td>\n",
       "      <td>9.8</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yield Curve  Production Index  Housing Starts  Cost of Living Index  \\\n",
       "Period                                                                        \n",
       "Jan.00         0.62          96.01601           118.4                  1466   \n",
       "Feb.00         0.53          96.31606           118.2                  1476   \n",
       "Mar.00         0.45          95.51592           118.4                  1485   \n",
       "Apr.00         0.22          97.01617           119.3                  1490   \n",
       "May.00         0.11         101.21690           120.5                  1497   \n",
       "\n",
       "        Unemployment  Consumer Price Index  \n",
       "Period                                      \n",
       "Jan.00          10.1                  98.0  \n",
       "Feb.00          10.2                  98.8  \n",
       "Mar.00          10.2                  99.3  \n",
       "Apr.00          10.0                  99.6  \n",
       "May.00           9.8                  99.9  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = pd.read_csv('Initial Data.csv', index_col=\"Period\")\n",
    "inflation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 277 entries, Jan.00 to Jan.23\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Yield Curve           277 non-null    float64\n",
      " 1   Production Index      277 non-null    float64\n",
      " 2   Housing Starts        277 non-null    float64\n",
      " 3   Cost of Living Index  277 non-null    int64  \n",
      " 4   Unemployment          277 non-null    float64\n",
      " 5   Consumer Price Index  277 non-null    float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 15.1+ KB\n"
     ]
    }
   ],
   "source": [
    "inflation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree (Unoptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.17828571428571438\n",
      "MAE of Decision Tree 0.254285714285713\n",
      "R-Squared of Decision Tree 0.9989019762554627\n"
     ]
    }
   ],
   "source": [
    "X = inflation.drop('Consumer Price Index', axis=1)\n",
    "y = inflation['Consumer Price Index']\n",
    "\n",
    "\n",
    "#creating the x and y value for the dataset and creating a test and training set from them\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit (X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "inflation_tree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of tree: 11\n",
      "Number of nodes in tree: 311\n"
     ]
    }
   ],
   "source": [
    "print('Depth of tree:', inflation_tree.tree_.max_depth)\n",
    "print('Number of nodes in tree:', inflation_tree.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param: {'max_depth': 8, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "param_dt = {'max_depth': [2, 4, 6, 8, 10, 11], 'min_samples_leaf': [1, 2, 5, 10, 15, 20, 25]}\n",
    "grid_dt = GridSearchCV(estimator=inflation_tree, param_grid=param_dt, scoring='neg_mean_squared_error')\n",
    "grid_result = grid_dt.fit(X_train_scaled, y_train)\n",
    "print ('Best Param:', grid_result.best_params_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.17828571428571438\n",
      "MAE of Decision Tree 0.254285714285713\n",
      "R-Squared of Decision Tree 0.9989019762554627\n"
     ]
    }
   ],
   "source": [
    "inflation_tree = DecisionTreeRegressor(random_state=42, max_depth=11, min_samples_leaf=1)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.20709222142860118\n",
      "MAE of Random Forest: 0.22328571428571828\n",
      "R-squared 0.9987245631129303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "inflation_random.fit(X_train_scaled, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test_scaled)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result is obtained using {'max_depth': 10, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(max_depth = [1, 5, 10, 15], min_samples_leaf = [1, 5, 10, 15, 20])\n",
    "\n",
    "forest_est = RandomForestRegressor(n_estimators = 200, random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=inflation_random, param_grid=grid, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is obtained using\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.2553169205601701\n",
      "MAE of Random Forest: 0.24244551020409924\n",
      "R-squared 0.9984275574614581\n"
     ]
    }
   ],
   "source": [
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=10, min_samples_leaf=1)\n",
    "inflation_random.fit(X_train, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0q/7yfv43d952dbrjwdnvllyvq40000gn/T/ipykernel_33340/3106147700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minflation_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minflation_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minflation_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmse_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lasso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(alpha=0.1, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO After Manual Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 0.00681481976052625\n",
      "MAE of LASSO Forest: 0.041498808482829476\n",
      "R-Squared of Lasso 0.9999580289764562\n"
     ]
    }
   ],
   "source": [
    "#After manual tuning\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(alpha=0.001, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.65326160964029\n",
      "MAE: 2.6037055553570068\n",
      "R-squared: 0.9431157526935037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Initial Data.csv')\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = data[['Yield Curve', 'Production Index', 'Housing Starts', 'Cost of Living Index', 'Unemployment']]\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVR model with chosen hyperparameters\n",
    "svr = SVR(kernel='linear', C=1, epsilon=0.01)\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'epsilon': 0.01, 'kernel': 'linear'}\n",
      "SVR(C=10, epsilon=0.01, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = inflation\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = data[['Yield Curve', 'Production Index', 'Housing Starts', 'Cost of Living Index', 'Unemployment']]\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a dictionary of hyperparameters and their possible values\n",
    "param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 2, 3, 4, 5, 10], 'epsilon': [0.01, 0.1, 1]}\n",
    "\n",
    "# Create an SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Use GridSearchCV to find the best combination of hyperparameters\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print (best_params)\n",
    "print (best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized SVR after Manual Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007804155513819126\n",
      "MAE: 0.04485142497050496\n",
      "R-squared: 0.9999486975510169\n"
     ]
    }
   ],
   "source": [
    "svr = SVR (C=20, epsilon=0.0341, kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield Curve</th>\n",
       "      <th>Production Index</th>\n",
       "      <th>Housing Starts</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Consumer Price Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan.00</th>\n",
       "      <td>0.62</td>\n",
       "      <td>96.01601</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1466</td>\n",
       "      <td>10.1</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb.00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>96.31606</td>\n",
       "      <td>118.2</td>\n",
       "      <td>1476</td>\n",
       "      <td>10.2</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar.00</th>\n",
       "      <td>0.45</td>\n",
       "      <td>95.51592</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1485</td>\n",
       "      <td>10.2</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr.00</th>\n",
       "      <td>0.22</td>\n",
       "      <td>97.01617</td>\n",
       "      <td>119.3</td>\n",
       "      <td>1490</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May.00</th>\n",
       "      <td>0.11</td>\n",
       "      <td>101.21690</td>\n",
       "      <td>120.5</td>\n",
       "      <td>1497</td>\n",
       "      <td>9.8</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yield Curve  Production Index  Housing Starts  Cost of Living Index  \\\n",
       "Period                                                                        \n",
       "Jan.00         0.62          96.01601           118.4                  1466   \n",
       "Feb.00         0.53          96.31606           118.2                  1476   \n",
       "Mar.00         0.45          95.51592           118.4                  1485   \n",
       "Apr.00         0.22          97.01617           119.3                  1490   \n",
       "May.00         0.11         101.21690           120.5                  1497   \n",
       "\n",
       "        Unemployment  Consumer Price Index  \n",
       "Period                                      \n",
       "Jan.00          10.1                  98.0  \n",
       "Feb.00          10.2                  98.8  \n",
       "Mar.00          10.2                  99.3  \n",
       "Apr.00          10.0                  99.6  \n",
       "May.00           9.8                  99.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('Initial Data.csv', index_col='Period')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Consumer Price Index', axis=1)\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit (X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.005, 0.0005, 0.05, 0.1, 0.15],\n",
    "              'max_depth': [1, 2, 3, 4, 5],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost Unoptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/0q/7yfv43d952dbrjwdnvllyvq40000gn/T/ipykernel_49907/3545485041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg:squarederror'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_xg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0mmse_xg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_xg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[0mmae_xg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_xg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_xg = xgb_model.predict(X_test_scaled)\n",
    "mse_xg = mse(y_test, y_pred_xg )\n",
    "mae_xg = mae(y_test, y_pred_xg )\n",
    "rsq_xg = r2s(y_test, y_pred_xg )\n",
    "print('MSE: ', mse_xg)\n",
    "print ('MAE: ', mae_xg)\n",
    "print ('R-squared: ', rsq_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    n_estimators=1000, n_jobs=None,\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.005, 0.0005, 0.05, 0.1, 0.15],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'min_child_weight': [1, 2, 3, 4, 5]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1}\n",
      "Best mean squared error: 0.1307192546575024\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best mean squared error:', -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=3, min_child_weight=1)\n",
    "xgb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.09411105604273555\n",
      "MAE:  0.20003764561244425\n",
      "R-squared:  0.999420390048791\n"
     ]
    }
   ],
   "source": [
    "y_pred_xg = xgb_model.predict(X_test_scaled)\n",
    "mse_xg = mse(y_test, y_pred_xg )\n",
    "mae_xg = mae(y_test, y_pred_xg )\n",
    "rsq_xg = r2s(y_test, y_pred_xg )\n",
    "print('MSE: ', mse_xg)\n",
    "print ('MAE: ', mae_xg)\n",
    "print ('R-squared: ', rsq_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized MLP Regressor (Interation Increased for Network to Merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  30.136037147075797\n",
      "Mean Absolute Error:  4.223595006133948\n",
      "R-squared:  0.8143985653235436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the artificial neural network\n",
    "#model = MLPRegressor(hidden_layer_sizes=(50, 50), activation='relu',max_iter=2000, alpha=0.01, random_state=42)\n",
    "model = MLPRegressor(random_state=42, max_iter=3000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the Consumer Price Index using the trained model\n",
    "y_pred_mlp = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_mlp = mse(y_test, y_pred_mlp)\n",
    "mae_mlp = mae(y_test, y_pred_mlp)\n",
    "rsq_mlp = r2s(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print('Mean Squared Error: ', mse_mlp)\n",
    "print('Mean Absolute Error: ', mae_mlp)\n",
    "print('R-squared: ', rsq_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized MLP Regressor after Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.005138004622001014\n",
      "Mean Absolute Error:  0.04378723011136917\n",
      "R-squared:  0.9999683561237809\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "\n",
    "\n",
    "# Train the artificial neural network\n",
    "model = MLPRegressor(hidden_layer_sizes=(50, 50), activation='relu', solver='lbfgs', max_iter=4000, learning_rate='constant', alpha=0.01, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the Consumer Price Index using the trained model\n",
    "y_pred_mlp = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_mlp = mse(y_test, y_pred_mlp)\n",
    "mae_mlp = mae(y_test, y_pred_mlp)\n",
    "rsq_mlp = r2s(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print('Mean Squared Error: ', mse_mlp)\n",
    "print('Mean Absolute Error: ', mae_mlp)\n",
    "print('R-squared: ', rsq_mlp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
