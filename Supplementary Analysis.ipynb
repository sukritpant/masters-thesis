{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield Curve</th>\n",
       "      <th>Production Index</th>\n",
       "      <th>Housing Starts</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Business Confidence</th>\n",
       "      <th>Producer Price Index</th>\n",
       "      <th>Export Price Index</th>\n",
       "      <th>Import Price Index</th>\n",
       "      <th>Basic Price Index for Domestic Goods</th>\n",
       "      <th>USD</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>CNY</th>\n",
       "      <th>OMX Helsinki</th>\n",
       "      <th>Consumer Price Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan.00</th>\n",
       "      <td>0.62</td>\n",
       "      <td>96.01601</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1466</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13</td>\n",
       "      <td>91.1</td>\n",
       "      <td>110.2</td>\n",
       "      <td>85.9</td>\n",
       "      <td>79.1</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>106.53</td>\n",
       "      <td>0.61834</td>\n",
       "      <td>8.3926</td>\n",
       "      <td>14364.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb.00</th>\n",
       "      <td>0.53</td>\n",
       "      <td>96.31606</td>\n",
       "      <td>118.2</td>\n",
       "      <td>1476</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20</td>\n",
       "      <td>92.9</td>\n",
       "      <td>113.3</td>\n",
       "      <td>87.2</td>\n",
       "      <td>79.9</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>107.64</td>\n",
       "      <td>0.61466</td>\n",
       "      <td>8.1408</td>\n",
       "      <td>15864.0</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar.00</th>\n",
       "      <td>0.45</td>\n",
       "      <td>95.51592</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1485</td>\n",
       "      <td>10.2</td>\n",
       "      <td>17</td>\n",
       "      <td>93.5</td>\n",
       "      <td>114.4</td>\n",
       "      <td>87.9</td>\n",
       "      <td>80.3</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>102.59</td>\n",
       "      <td>0.61063</td>\n",
       "      <td>7.9834</td>\n",
       "      <td>17092.0</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr.00</th>\n",
       "      <td>0.22</td>\n",
       "      <td>97.01617</td>\n",
       "      <td>119.3</td>\n",
       "      <td>1490</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>93.9</td>\n",
       "      <td>115.1</td>\n",
       "      <td>87.4</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>99.92</td>\n",
       "      <td>0.59802</td>\n",
       "      <td>7.8402</td>\n",
       "      <td>15799.0</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May.00</th>\n",
       "      <td>0.11</td>\n",
       "      <td>101.21690</td>\n",
       "      <td>120.5</td>\n",
       "      <td>1497</td>\n",
       "      <td>9.8</td>\n",
       "      <td>19</td>\n",
       "      <td>93.8</td>\n",
       "      <td>114.6</td>\n",
       "      <td>89.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>98.09</td>\n",
       "      <td>0.60151</td>\n",
       "      <td>7.4996</td>\n",
       "      <td>16344.0</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yield Curve  Production Index  Housing Starts  Cost of Living Index  \\\n",
       "Period                                                                        \n",
       "Jan.00         0.62          96.01601           118.4                  1466   \n",
       "Feb.00         0.53          96.31606           118.2                  1476   \n",
       "Mar.00         0.45          95.51592           118.4                  1485   \n",
       "Apr.00         0.22          97.01617           119.3                  1490   \n",
       "May.00         0.11         101.21690           120.5                  1497   \n",
       "\n",
       "        Unemployment  Business Confidence  Producer Price Index  \\\n",
       "Period                                                            \n",
       "Jan.00          10.1                   13                  91.1   \n",
       "Feb.00          10.2                   20                  92.9   \n",
       "Mar.00          10.2                   17                  93.5   \n",
       "Apr.00          10.0                   15                  93.9   \n",
       "May.00           9.8                   19                  93.8   \n",
       "\n",
       "        Export Price Index  Import Price Index  \\\n",
       "Period                                           \n",
       "Jan.00               110.2                85.9   \n",
       "Feb.00               113.3                87.2   \n",
       "Mar.00               114.4                87.9   \n",
       "Apr.00               115.1                87.4   \n",
       "May.00               114.6                89.2   \n",
       "\n",
       "        Basic Price Index for Domestic Goods     USD     JPY      GBP     CNY  \\\n",
       "Period                                                                          \n",
       "Jan.00                                  79.1  1.0137  106.53  0.61834  8.3926   \n",
       "Feb.00                                  79.9  0.9834  107.64  0.61466  8.1408   \n",
       "Mar.00                                  80.3  0.9643  102.59  0.61063  7.9834   \n",
       "Apr.00                                  80.2  0.9470   99.92  0.59802  7.8402   \n",
       "May.00                                  81.0  0.9060   98.09  0.60151  7.4996   \n",
       "\n",
       "        OMX Helsinki  Consumer Price Index  \n",
       "Period                                      \n",
       "Jan.00       14364.0                  98.0  \n",
       "Feb.00       15864.0                  98.8  \n",
       "Mar.00       17092.0                  99.3  \n",
       "Apr.00       15799.0                  99.6  \n",
       "May.00       16344.0                  99.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = pd.read_csv('Additional.csv', index_col=\"Period\")\n",
    "inflation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 277 entries, Jan.00 to Jan.23\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Yield Curve                           277 non-null    float64\n",
      " 1   Production Index                      277 non-null    float64\n",
      " 2   Housing Starts                        277 non-null    float64\n",
      " 3   Cost of Living Index                  277 non-null    int64  \n",
      " 4   Unemployment                          277 non-null    float64\n",
      " 5   Business Confidence                   277 non-null    int64  \n",
      " 6   Producer Price Index                  277 non-null    float64\n",
      " 7   Export Price Index                    277 non-null    float64\n",
      " 8   Import Price Index                    277 non-null    float64\n",
      " 9   Basic Price Index for Domestic Goods  277 non-null    float64\n",
      " 10  USD                                   277 non-null    float64\n",
      " 11  JPY                                   277 non-null    float64\n",
      " 12  GBP                                   277 non-null    float64\n",
      " 13  CNY                                   277 non-null    float64\n",
      " 14  OMX Helsinki                          277 non-null    float64\n",
      " 15  Consumer Price Index                  277 non-null    float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 36.8+ KB\n"
     ]
    }
   ],
   "source": [
    "inflation['OMX Helsinki'] = pd.to_numeric(inflation['OMX Helsinki']).astype(float)\n",
    "inflation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.3558571428571424\n",
      "MAE of Decision Tree 0.3414285714285709\n",
      "R-Squared of Decision Tree 0.9978083516445174\n"
     ]
    }
   ],
   "source": [
    "X = inflation.drop('Consumer Price Index', axis=1)\n",
    "y = inflation['Consumer Price Index']\n",
    "\n",
    "\n",
    "#creating the x and y value for the dataset and creating a test and training set from them\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit (X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "inflation_tree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of tree: 10\n",
      "Number of nodes in tree: 299\n"
     ]
    }
   ],
   "source": [
    "print('Depth of tree:', inflation_tree.tree_.max_depth)\n",
    "print('Number of nodes in tree:', inflation_tree.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param: {'max_depth': 8, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "param_dt = {'max_depth': [2, 4, 6, 8, 10], 'min_samples_leaf': [1, 2, 5, 10, 15, 20, 25]}\n",
    "grid_dt = GridSearchCV(estimator=inflation_tree, param_grid=param_dt, scoring='neg_mean_squared_error')\n",
    "grid_result = grid_dt.fit(X_train_scaled, y_train)\n",
    "print ('Best Param:', grid_result.best_params_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized for New Variables for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.7190992063492055\n",
      "MAE of Decision Tree 0.44899999999999846\n",
      "R-Squared of Decision Tree 0.9955712211356209\n"
     ]
    }
   ],
   "source": [
    "inflation_tree = DecisionTreeRegressor(random_state=42, max_depth=8, min_samples_leaf=1)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization from Initial Dataset for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Decision Tree:  0.3558571428571424\n",
      "MAE of Decision Tree 0.3414285714285709\n",
      "R-Squared of Decision Tree 0.9978083516445174\n"
     ]
    }
   ],
   "source": [
    "inflation_tree = DecisionTreeRegressor(random_state=42, max_depth=10, min_samples_leaf=1)\n",
    "\n",
    "inflation_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_decision = inflation_tree.predict(X_test_scaled)\n",
    "mse_tree = mse(y_test, y_pred_decision)\n",
    "mae_tree = mae(y_test, y_pred_decision)\n",
    "rsq_tree = r2s(y_test, y_pred_decision)\n",
    "print ('MSE of Decision Tree: ', mse_tree)\n",
    "print ('MAE of Decision Tree', mae_tree)\n",
    "print ('R-Squared of Decision Tree', rsq_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.20444984285718612\n",
      "MAE of Random Forest: 0.26469999999999955\n",
      "R-squared 0.9987408369598008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "inflation_random.fit(X_train_scaled, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test_scaled)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result is obtained using {'max_depth': 15, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(max_depth = [1, 5, 10, 15], min_samples_leaf = [1, 5, 10, 15, 20])\n",
    "\n",
    "forest_est = RandomForestRegressor(n_estimators = 200, random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=inflation_random, param_grid=grid, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is obtained using\", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized Random Forest for New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.20119588200003288\n",
      "MAE of Random Forest: 0.25219571428572163\n",
      "R-squared 0.9987608774117195\n"
     ]
    }
   ],
   "source": [
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=10, min_samples_leaf=1)\n",
    "inflation_random.fit(X_train, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized Random Forest from Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest: 0.19576792142859478\n",
      "MAE of Random Forest: 0.26337142857144347\n",
      "R-squared 0.9987943070648789\n"
     ]
    }
   ],
   "source": [
    "inflation_random = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=15, min_samples_leaf=1)\n",
    "inflation_random.fit(X_train, y_train)\n",
    "y_pred_rand = inflation_random.predict(X_test)\n",
    "mse_rand = mse(y_test, y_pred_rand)\n",
    "mae_rand = mae(y_test, y_pred_rand)\n",
    "r2 = r2s(y_test, y_pred_rand)\n",
    "print ('MSE of Random Forest:',mse_rand )\n",
    "print ('MAE of Random Forest:',mae_rand )\n",
    "print ('R-squared', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 0.25190844904734055\n",
      "MAE of LASSO Forest: 0.43970521711984534\n",
      "R-Squared of Lasso 0.9984485495115988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(alpha=0.1, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized LASSO for Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of LASSO: 0.007651088626041924\n",
      "MAE of LASSO Forest: 0.042575130452416336\n",
      "R-Squared of Lasso 0.9999528785746149\n"
     ]
    }
   ],
   "source": [
    "#After manual tuning\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "inflation_lasso = Lasso(alpha=0.001, random_state=42)\n",
    "inflation_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = inflation_lasso.predict(X_test_scaled)\n",
    "mse_lasso = mse(y_test, y_pred_lasso)\n",
    "mae_lasso = mae(y_test, y_pred_lasso)\n",
    "r2_lasso = r2s(y_test, y_pred_lasso)\n",
    "print ('MSE of LASSO:',mse_lasso )\n",
    "print ('MAE of LASSO Forest:',mae_lasso )\n",
    "print ('R-Squared of Lasso', r2_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.479701712622173\n",
      "MAE: 1.2756012057733819\n",
      "R-squared: 0.9836990984636363\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = inflation.drop('Consumer Price Index', axis=1)\n",
    "y = inflation['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVR model with chosen hyperparameters\n",
    "svr = SVR(kernel='linear', C=1, epsilon=0.01)\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'epsilon': 0.01, 'kernel': 'linear'}\n",
      "SVR(C=10, epsilon=0.01, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = inflation\n",
    "\n",
    "# Extract the X and Y columns\n",
    "X = inflation.drop('Consumer Price Index', axis=1)\n",
    "y = inflation['Consumer Price Index']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the X data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a dictionary of hyperparameters and their possible values\n",
    "param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 2, 3, 4, 5, 10], 'epsilon': [0.01, 0.1, 1]}\n",
    "\n",
    "# Create an SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Use GridSearchCV to find the best combination of hyperparameters\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print (best_params)\n",
    "print (best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized for New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009146208037214203\n",
      "MAE: 0.05205595167807617\n",
      "R-squared: 0.9999398752535893\n"
     ]
    }
   ],
   "source": [
    "svr = SVR (C=50, epsilon=0.01, kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized SVR for Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013310750355821308\n",
      "MAE: 0.0768395063064267\n",
      "R-squared: 0.9999124986566647\n"
     ]
    }
   ],
   "source": [
    "svr = SVR (C=20, epsilon=0.0341, kernel='linear')\n",
    "\n",
    "# Train the SVR model on the training data\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R-squared:', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/0q/7yfv43d952dbrjwdnvllyvq40000gn/T/ipykernel_70919/3338148307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Additional.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Period'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('Additional.csv', index_col='Period')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 277 entries, Jan.00 to Jan.23\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Yield Curve                           277 non-null    float64\n",
      " 1   Production Index                      277 non-null    float64\n",
      " 2   Housing Starts                        277 non-null    float64\n",
      " 3   Cost of Living Index                  277 non-null    int64  \n",
      " 4   Unemployment                          277 non-null    float64\n",
      " 5   Business Confidence                   277 non-null    int64  \n",
      " 6   Producer Price Index                  277 non-null    float64\n",
      " 7   Export Price Index                    277 non-null    float64\n",
      " 8   Import Price Index                    277 non-null    float64\n",
      " 9   Basic Price Index for Domestic Goods  277 non-null    float64\n",
      " 10  USD                                   277 non-null    float64\n",
      " 11  JPY                                   277 non-null    float64\n",
      " 12  GBP                                   277 non-null    float64\n",
      " 13  CNY                                   277 non-null    float64\n",
      " 14  OMX Helsinki                          277 non-null    float64\n",
      " 15  Consumer Price Index                  277 non-null    float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 36.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Consumer Price Index', axis=1)\n",
    "y = data['Consumer Price Index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit (X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.005, 0.0005, 0.05, 0.1, 0.15],\n",
    "              'max_depth': [1, 2, 3, 4, 5],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.415730045874669\n",
      "MAE:  0.4601597813197537\n",
      "R-squared:  0.9974396071860452\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000) \n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_xg = xgb_model.predict(X_test_scaled)\n",
    "mse_xg = mse(y_test, y_pred_xg )\n",
    "mae_xg = mae(y_test, y_pred_xg )\n",
    "rsq_xg = r2s(y_test, y_pred_xg )\n",
    "print('MSE: ', mse_xg)\n",
    "print ('MAE: ', mae_xg)\n",
    "print ('R-squared: ', rsq_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    n_estimators=1000, n_jobs=None,\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.005, 0.0005, 0.05, 0.1, 0.15],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'min_child_weight': [1, 2, 3, 4, 5]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1}\n",
      "Best mean squared error: 0.12879385858217382\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best mean squared error:', -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized XG Boost for New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/0q/7yfv43d952dbrjwdnvllyvq40000gn/T/ipykernel_70919/1788148898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg:squarederror'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=3, min_child_weight=1)\n",
    "xgb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.09012867526014887\n",
      "MAE:  0.1977616446358819\n",
      "R-squared:  0.999444916683898\n"
     ]
    }
   ],
   "source": [
    "y_pred_xg = xgb_model.predict(X_test_scaled)\n",
    "mse_xg = mse(y_test, y_pred_xg )\n",
    "mae_xg = mae(y_test, y_pred_xg )\n",
    "rsq_xg = r2s(y_test, y_pred_xg )\n",
    "print('MSE: ', mse_xg)\n",
    "print ('MAE: ', mae_xg)\n",
    "print ('R-squared: ', rsq_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized SVR for Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.07003671016391108\n",
      "MAE:  0.1549116298130581\n",
      "R-squared:  0.9995686588179129\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=4000, learning_rate=0.005, max_depth=20, min_child_weight=1)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_xg = xgb_model.predict(X_test_scaled)\n",
    "mse_xg = mse(y_test, y_pred_xg )\n",
    "mae_xg = mae(y_test, y_pred_xg )\n",
    "rsq_xg = r2s(y_test, y_pred_xg )\n",
    "print('MSE: ', mse_xg)\n",
    "print ('MAE: ', mae_xg)\n",
    "print ('R-squared: ', rsq_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  73.77729708704925\n",
      "Mean Absolute Error:  6.7491086082453435\n",
      "R-squared:  0.545621339691102\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the artificial neural network\n",
    "model = MLPRegressor(hidden_layer_sizes=(50, 50), activation='relu',max_iter=500, alpha=0.01, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the Consumer Price Index using the trained model\n",
    "y_pred_mlp = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_mlp = mse(y_test, y_pred_mlp)\n",
    "mae_mlp = mae(y_test, y_pred_mlp)\n",
    "rsq_mlp = r2s(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print('Mean Squared Error: ', mse_mlp)\n",
    "print('Mean Absolute Error: ', mae_mlp)\n",
    "print('R-squared: ', rsq_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Optimization Performed on Google Colab due to resource constraint\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {\n",
    "'hidden_layer_sizes': [(10,), (50,), (100,), (10,10), (50,50), (100,100)],\n",
    "'activation': ['logistic', 'tanh', 'relu'],\n",
    "'solver': ['lbfgs', 'adam'],\n",
    "'learning_rate': ['constant', 'adaptive'],\n",
    "'max_iter': [1000, 2000, 3000, 4000, 5000]\n",
    "}\n",
    "grid_mlp = GridSearchCV(mlp, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized MLP for New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.005300868053561705\n",
      "Mean Absolute Error:  0.041139113347481424\n",
      "R-squared:  0.9999673530825911\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "\n",
    "\n",
    "# Train the artificial neural network\n",
    "model = MLPRegressor(hidden_layer_sizes=(100, 100), activation='relu', solver='lbfgs', max_iter=5000, learning_rate='adaptive', alpha=0.01, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the Consumer Price Index using the trained model\n",
    "y_pred_mlp = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_mlp = mse(y_test, y_pred_mlp)\n",
    "mae_mlp = mae(y_test, y_pred_mlp)\n",
    "rsq_mlp = r2s(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print('Mean Squared Error: ', mse_mlp)\n",
    "print('Mean Absolute Error: ', mae_mlp)\n",
    "print('R-squared: ', rsq_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized MLP for Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.004281388790105986\n",
      "Mean Absolute Error:  0.04059493730518824\n",
      "R-squared:  0.9999736318382548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2s\n",
    "\n",
    "\n",
    "# Train the artificial neural network\n",
    "model = MLPRegressor(hidden_layer_sizes=(50, 50), activation='relu', solver='lbfgs', max_iter=5000, learning_rate='constant', alpha=0.01, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the Consumer Price Index using the trained model\n",
    "y_pred_mlp = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_mlp = mse(y_test, y_pred_mlp)\n",
    "mae_mlp = mae(y_test, y_pred_mlp)\n",
    "rsq_mlp = r2s(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print('Mean Squared Error: ', mse_mlp)\n",
    "print('Mean Absolute Error: ', mae_mlp)\n",
    "print('R-squared: ', rsq_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
